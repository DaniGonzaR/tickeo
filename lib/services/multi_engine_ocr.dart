import 'dart:io';
import 'dart:convert';

import 'package:http/http.dart' as http;
import 'package:google_mlkit_text_recognition/google_mlkit_text_recognition.dart';
import 'package:flutter/foundation.dart';
import 'package:tickeo/models/ocr_models.dart';
import 'package:tickeo/services/image_preprocessor.dart';

/// Motor OCR multi-engine que combina varios servicios para m√°xima precisi√≥n
class MultiEngineOCR {
  static final MultiEngineOCR _instance = MultiEngineOCR._internal();
  factory MultiEngineOCR() => _instance;
  MultiEngineOCR._internal();

  TextRecognizer? _textRecognizer;

  /// Inicializar los motores OCR
  void initialize() {
    if (!kIsWeb) {
      _textRecognizer = TextRecognizer();
    }
  }

  /// Extrae texto usando m√∫ltiples engines y genera consenso
  Future<MultiEngineOCRResult> extractText(ProcessedImage processedImage) async {
    print('üîç INICIANDO EXTRACCI√ìN MULTI-ENGINE...');
    
    final results = <OCRResult>[];
    
    try {
      // Engine 1: Google ML Kit (m√≥vil)
      if (!kIsWeb && _textRecognizer != null) {
        final mlKitResult = await _extractWithMLKit(processedImage);
        if (mlKitResult != null) {
          results.add(mlKitResult);
        }
      }

      // Engine 2: OCR.space API (web y m√≥vil)
      final ocrSpaceResult = await _extractWithOCRSpace(processedImage);
      if (ocrSpaceResult != null) {
        results.add(ocrSpaceResult);
      }

      // Engine 3: Tesseract.js (web fallback)
      if (kIsWeb) {
        final tesseractResult = await _extractWithTesseract(processedImage);
        if (tesseractResult != null) {
          results.add(tesseractResult);
        }
      }

      // Engine 4: Azure Computer Vision (premium, opcional)
      // final azureResult = await _extractWithAzure(processedImage);
      // if (azureResult != null) results.add(azureResult);

    } catch (e) {
      print('‚ùå Error en extracci√≥n multi-engine: $e');
    }

    if (results.isEmpty) {
      throw Exception('Todos los motores OCR fallaron');
    }

    // Generar consenso entre resultados
    final consensusResult = _generateConsensus(results);
    
    print('‚úÖ EXTRACCI√ìN MULTI-ENGINE COMPLETADA');
    print('üìä Engines exitosos: ${results.length}');
    print('üéØ Confianza general: ${consensusResult.overallConfidence.toStringAsFixed(2)}');
    
    return consensusResult;
  }

  /// Extrae texto usando Google ML Kit
  Future<OCRResult?> _extractWithMLKit(ProcessedImage image) async {
    if (kIsWeb || _textRecognizer == null) return null;
    
    print('üì± Extrayendo con Google ML Kit...');
    
    try {
      // Crear archivo temporal para ML Kit
      final tempFile = File.fromRawPath(image.processedBytes);
      final inputImage = InputImage.fromFile(tempFile);
      
      final recognizedText = await _textRecognizer!.processImage(inputImage);
      
      // Calcular confianza basada en la cantidad y calidad del texto
      final confidence = _calculateMLKitConfidence(recognizedText);
      
      print('‚úÖ ML Kit extrajo ${recognizedText.text.length} caracteres (confianza: ${confidence.toStringAsFixed(2)})');
      
      return OCRResult(
        extractedText: recognizedText.text,
        confidence: confidence,
        engine: 'ml_kit',
        metadata: {
          'blocks': recognizedText.blocks.length,
          'lines': recognizedText.blocks.fold<int>(0, (sum, block) => sum + block.lines.length),
          'elements': recognizedText.blocks.fold<int>(0, (sum, block) => 
            sum + block.lines.fold<int>(0, (lineSum, line) => lineSum + line.elements.length)),
        },
      );
      
    } catch (e) {
      print('‚ùå Error en ML Kit: $e');
      return null;
    }
  }

  /// Extrae texto usando OCR.space API
  Future<OCRResult?> _extractWithOCRSpace(ProcessedImage image) async {
    print('üåê Extrayendo con OCR.space...');
    
    try {
      final base64Image = base64Encode(image.processedBytes);
      
      final response = await http.post(
        Uri.parse('https://api.ocr.space/parse/image'),
        headers: {'Content-Type': 'application/x-www-form-urlencoded'},
        body: {
          'apikey': 'helloworld', // Free tier
          'base64Image': 'data:image/png;base64,$base64Image',
          'language': 'spa',
          'isOverlayRequired': 'false',
          'detectOrientation': 'true',
          'scale': 'true',
          'OCREngine': '2',
          'isTable': 'true', // Mejor para tickets estructurados
        },
      ).timeout(const Duration(seconds: 30));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        
        if (data['ParsedResults'] != null && data['ParsedResults'].isNotEmpty) {
          final extractedText = data['ParsedResults'][0]['ParsedText'] ?? '';
          final confidence = _calculateOCRSpaceConfidence(data);
          
          print('‚úÖ OCR.space extrajo ${extractedText.length} caracteres (confianza: ${confidence.toStringAsFixed(2)})');
          
          return OCRResult(
            extractedText: extractedText,
            confidence: confidence,
            engine: 'ocr_space',
            metadata: {
              'processingTimeInMilliseconds': data['ProcessingTimeInMilliseconds'],
              'isErroredOnProcessing': data['IsErroredOnProcessing'],
              'ocrExitCode': data['OCRExitCode'],
            },
          );
        }
      }
      
      print('‚ùå OCR.space fall√≥: ${response.statusCode}');
      return null;
      
    } catch (e) {
      print('‚ùå Error en OCR.space: $e');
      return null;
    }
  }

  /// Extrae texto usando Tesseract.js (web)
  Future<OCRResult?> _extractWithTesseract(ProcessedImage image) async {
    if (!kIsWeb) return null;
    
    print('üï∏Ô∏è Extrayendo con Tesseract.js...');
    
    try {
      // Implementaci√≥n simplificada - en producci√≥n usar√≠amos Tesseract.js real
      // Por ahora, simulamos el resultado
      
      // TODO: Integrar Tesseract.js real para web
      // const tesseract = require('tesseract.js');
      // const result = await tesseract.recognize(image.processedBytes, 'spa');
      
      // Simulaci√≥n temporal
      await Future.delayed(const Duration(seconds: 2));
      
      print('‚ö†Ô∏è Tesseract.js no implementado completamente (simulaci√≥n)');
      return null;
      
    } catch (e) {
      print('‚ùå Error en Tesseract.js: $e');
      return null;
    }
  }

  /// Calcula la confianza para ML Kit basada en la estructura del texto
  double _calculateMLKitConfidence(RecognizedText recognizedText) {
    if (recognizedText.text.isEmpty) return 0.0;
    
    double confidence = 0.5; // Base
    
    // Bonus por cantidad de texto
    if (recognizedText.text.length > 100) confidence += 0.1;
    if (recognizedText.text.length > 300) confidence += 0.1;
    
    // Bonus por estructura (bloques y l√≠neas)
    if (recognizedText.blocks.length > 5) confidence += 0.1;
    
    // Bonus por detecci√≥n de precios (patr√≥n ‚Ç¨)
    final priceMatches = RegExp(r'\d+[.,]\d{2}').allMatches(recognizedText.text);
    if (priceMatches.length > 2) confidence += 0.1;
    if (priceMatches.length > 5) confidence += 0.1;
    
    return confidence.clamp(0.0, 1.0);
  }

  /// Calcula la confianza para OCR.space basada en metadatos
  double _calculateOCRSpaceConfidence(Map<String, dynamic> data) {
    double confidence = 0.6; // Base m√°s alta para OCR.space
    
    // Penalizar si hay errores
    if (data['IsErroredOnProcessing'] == true) {
      confidence -= 0.3;
    }
    
    // Bonus por exit code exitoso
    if (data['OCRExitCode'] == 1) {
      confidence += 0.2;
    }
    
    // Bonus por tiempo de procesamiento razonable
    final processingTimeRaw = data['ProcessingTimeInMilliseconds'];
    int processingTime = 0;
    if (processingTimeRaw != null) {
      if (processingTimeRaw is int) {
        processingTime = processingTimeRaw;
      } else if (processingTimeRaw is String) {
        processingTime = int.tryParse(processingTimeRaw) ?? 0;
      }
    }
    if (processingTime > 0 && processingTime < 10000) {
      confidence += 0.1;
    }
    
    return confidence.clamp(0.0, 1.0);
  }

  /// Genera consenso entre m√∫ltiples resultados OCR
  MultiEngineOCRResult _generateConsensus(List<OCRResult> results) {
    print('ü§ù Generando consenso entre ${results.length} resultados...');
    
    // Ordenar por confianza
    results.sort((a, b) => b.confidence.compareTo(a.confidence));
    
    // El mejor resultado es el de mayor confianza
    final bestResult = results.first;
    
    // Generar texto de consenso
    String consensusText = bestResult.extractedText;
    
    // Si tenemos m√∫ltiples resultados, intentar mejorar el consenso
    if (results.length > 1) {
      consensusText = _improveTextWithConsensus(results);
    }
    
    // Calcular confianza general
    double overallConfidence = results.fold<double>(0.0, (sum, result) => sum + result.confidence) / results.length;
    
    // Bonus si m√∫ltiples engines coinciden
    if (results.length > 1) {
      final similarity = _calculateTextSimilarity(results[0].extractedText, results[1].extractedText);
      overallConfidence += similarity * 0.2;
    }
    
    overallConfidence = overallConfidence.clamp(0.0, 1.0);
    
    print('üìà Consenso generado - Confianza: ${overallConfidence.toStringAsFixed(2)}');
    
    return MultiEngineOCRResult(
      individualResults: results,
      bestResult: bestResult,
      consensusText: consensusText,
      overallConfidence: overallConfidence,
    );
  }

  /// Mejora el texto usando consenso entre m√∫ltiples resultados
  String _improveTextWithConsensus(List<OCRResult> results) {
    // Implementaci√≥n simplificada - usar el mejor resultado
    // En una implementaci√≥n completa, comparar√≠amos l√≠nea por l√≠nea
    
    String bestText = results.first.extractedText;
    
    // TODO: Implementar algoritmo de consenso m√°s sofisticado
    // - Comparar l√≠nea por l√≠nea
    // - Usar algoritmos de distancia de edici√≥n
    // - Corregir caracteres con mayor consenso
    
    return bestText;
  }

  /// Calcula la similitud entre dos textos (0.0 - 1.0)
  double _calculateTextSimilarity(String text1, String text2) {
    if (text1.isEmpty && text2.isEmpty) return 1.0;
    if (text1.isEmpty || text2.isEmpty) return 0.0;
    
    // Algoritmo simple de similitud basado en caracteres comunes
    final set1 = text1.toLowerCase().split('').toSet();
    final set2 = text2.toLowerCase().split('').toSet();
    
    final intersection = set1.intersection(set2).length;
    final union = set1.union(set2).length;
    
    return union > 0 ? intersection / union : 0.0;
  }

  /// Liberar recursos
  void dispose() {
    _textRecognizer?.close();
  }
}
