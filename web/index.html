<!DOCTYPE html>
<html>
<head>
  <!--
    If you are serving your web app in a path other than the root, change the
    href value below to reflect the base path you are serving from.

    The path provided below has to start and end with a slash "/" in order for
    it to work correctly.

    For more details:
    * https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base

    This is a placeholder for base href that will be replaced by the value of
    the `--base-href` argument provided to `flutter build`.
  -->
  <base href="$FLUTTER_BASE_HREF">

  <meta charset="UTF-8">
  <meta content="IE=Edge" http-equiv="X-UA-Compatible">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Split bills easily with friends. Scan receipts, add participants, and calculate payments automatically.">

  <!-- PWA meta tags -->
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  <meta name="apple-mobile-web-app-title" content="Tickeo">
  <meta name="theme-color" content="#6366F1">
  
  <!-- iOS icons -->
  <link rel="apple-touch-icon" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="180x180" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="167x167" href="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>
  <link rel="shortcut icon" href="favicon.png">

  <title>Tickeo - Bill Splitter</title>
  <link rel="manifest" href="manifest.json">
  
  <!-- Tesseract.js for OCR functionality -->
  <script src="https://unpkg.com/tesseract.js@v5.0.0/dist/tesseract.min.js"></script>
  <script>
    // Initialize OCR systems
    console.log(' Initializing robust OCR system...');
    
    // Strategy 1: Advanced Tesseract.js with error handling
    window.processImageWithOCR = async function(imageFile) {
      try {
        console.log(' STRATEGY 1: Advanced Tesseract.js OCR starting...');
        console.log(' Image file type:', typeof imageFile);
        console.log(' Image file details:', imageFile);
        
        // Handle different types of image input
        let imageToProcess = imageFile;
        
        // If it's a File object or Blob, use it directly
        if (imageFile instanceof File || imageFile instanceof Blob) {
          console.log(' Processing File/Blob object');
          imageToProcess = imageFile;
        }
        // If it's a base64 string, use it directly
        else if (typeof imageFile === 'string' && imageFile.startsWith('data:')) {
          console.log(' Processing base64 string');
          imageToProcess = imageFile;
        }
        // If it's a URL or path, fetch it
        else if (typeof imageFile === 'string') {
          console.log(' Processing URL/path string');
          const response = await fetch(imageFile);
          imageToProcess = await response.blob();
        }
        else {
          console.error(' Unsupported image format:', typeof imageFile);
          throw new Error('Unsupported image format');
        }
        
        console.log(' Creating Tesseract worker...');
        
        // Create worker with optimized settings for receipts
        const worker = await Tesseract.createWorker('spa', 1, {
          logger: m => {
            console.log(' OCR Progress:', m.status, Math.round(m.progress * 100) + '%');
          }
        });
        
        // Set parameters optimized for receipt text
        await worker.setParameters({
          'tessedit_char_whitelist': '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú .,:-‚Ç¨$',
          'tessedit_pageseg_mode': '6', // Uniform block of text
        });
        
        console.log(' Processing image with optimized Tesseract...');
        
        // Process the image with timeout
        const { data: { text, confidence } } = await Promise.race([
          worker.recognize(imageToProcess),
          new Promise((_, reject) => 
            setTimeout(() => reject(new Error('OCR timeout')), 30000)
          )
        ]);
        
        console.log(' OCR completed successfully!');
        console.log(' Confidence:', confidence);
        console.log(' Extracted text length:', text.length);
        console.log(' Extracted text:', text);
        
        // Terminate worker to free memory
        await worker.terminate();
        
        // Return the extracted text
        return text;
      } catch (error) {
        console.error(' Advanced Tesseract OCR failed:', error);
        throw error;
      }
    };
    
    // üìê LEVEL 1: Automatic Perspective Correction for Tickets
    window.correctPerspective = function(base64Image) {
      return new Promise((resolve, reject) => {
        try {
          console.log('üìê Starting automatic perspective correction...');
          
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          const img = new Image();
          
          img.onload = function() {
            console.log('üì∏ Image loaded for perspective correction');
            
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            
            // Get image data for edge detection
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            
            // Step 1: Convert to grayscale for edge detection
            const grayData = convertToGrayscale(imageData);
            console.log('‚ö´ Converted to grayscale for edge detection');
            
            // Step 2: Apply Gaussian blur to reduce noise
            const blurredData = applyGaussianBlur(grayData, canvas.width, canvas.height);
            console.log('üå´Ô∏è Applied Gaussian blur');
            
            // Step 3: Detect edges using Canny edge detection
            const edges = detectEdges(blurredData, canvas.width, canvas.height);
            console.log('üîç Detected edges');
            
            // Step 4: Find ticket contours (rectangular shapes)
            const ticketCorners = findTicketCorners(edges, canvas.width, canvas.height);
            
            if (ticketCorners && ticketCorners.length === 4) {
              console.log('üìÑ Ticket corners detected:', ticketCorners);
              
              // LEVEL 1: Apply perspective correction first
              const perspectiveCorrected = applyPerspectiveTransform(canvas, ticketCorners);
              console.log('üìê Perspective correction completed');
              
              // LEVEL 2: Detect and focus on text regions
              const textFocused = detectTextRegions(perspectiveCorrected);
              console.log('üîç Text region detection completed');
              
              // PHASE 1: Apply advanced preprocessing
              const preprocessedImage = preprocessImageForOCR(textFocused);
              console.log('‚úÖ Image preprocessing completed');
              
              resolve(preprocessedImage);
            } else {
              console.log('‚ö†Ô∏è Could not detect ticket corners, using original image');
              resolve(base64Image); // Fallback to original
            }
          };
          
          img.onerror = function() {
            console.error('‚ùå Failed to load image for perspective correction');
            resolve(base64Image); // Fallback to original
          };
          
          img.src = base64Image;
          
        } catch (error) {
          console.error('‚ùå Perspective correction failed:', error);
          resolve(base64Image); // Fallback to original
        }
      });
    };
    
    // Helper functions for perspective correction
    function convertToGrayscale(imageData) {
      const data = new Uint8ClampedArray(imageData.data);
      for (let i = 0; i < data.length; i += 4) {
        const gray = Math.round(0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2]);
        data[i] = gray;
        data[i + 1] = gray;
        data[i + 2] = gray;
      }
      return data;
    }
    
    function applyGaussianBlur(data, width, height) {
      // Simple 3x3 Gaussian kernel
      const kernel = [1, 2, 1, 2, 4, 2, 1, 2, 1];
      const kernelSum = 16;
      const result = new Uint8ClampedArray(data.length);
      
      for (let y = 1; y < height - 1; y++) {
        for (let x = 1; x < width - 1; x++) {
          let sum = 0;
          for (let ky = -1; ky <= 1; ky++) {
            for (let kx = -1; kx <= 1; kx++) {
              const idx = ((y + ky) * width + (x + kx)) * 4;
              const kernelIdx = (ky + 1) * 3 + (kx + 1);
              sum += data[idx] * kernel[kernelIdx];
            }
          }
          const idx = (y * width + x) * 4;
          const blurred = sum / kernelSum;
          result[idx] = blurred;
          result[idx + 1] = blurred;
          result[idx + 2] = blurred;
          result[idx + 3] = data[idx + 3];
        }
      }
      return result;
    }
    
    function detectEdges(data, width, height) {
      // Sobel edge detection
      const sobelX = [-1, 0, 1, -2, 0, 2, -1, 0, 1];
      const sobelY = [-1, -2, -1, 0, 0, 0, 1, 2, 1];
      const edges = new Uint8ClampedArray(width * height);
      
      for (let y = 1; y < height - 1; y++) {
        for (let x = 1; x < width - 1; x++) {
          let gx = 0, gy = 0;
          
          for (let ky = -1; ky <= 1; ky++) {
            for (let kx = -1; kx <= 1; kx++) {
              const idx = ((y + ky) * width + (x + kx)) * 4;
              const kernelIdx = (ky + 1) * 3 + (kx + 1);
              const pixel = data[idx];
              gx += pixel * sobelX[kernelIdx];
              gy += pixel * sobelY[kernelIdx];
            }
          }
          
          const magnitude = Math.sqrt(gx * gx + gy * gy);
          edges[y * width + x] = magnitude > 50 ? 255 : 0; // Threshold
        }
      }
      return edges;
    }
    
    function findTicketCorners(edges, width, height) {
      // Simplified corner detection - look for rectangular contours
      console.log('üîç Searching for ticket corners...');
      
      // Find the largest rectangular contour (likely the ticket)
      const corners = [];
      
      // Simple heuristic: look for corners in quadrants
      const quadrants = [
        { x: 0, y: 0, w: width/2, h: height/2 }, // Top-left
        { x: width/2, y: 0, w: width/2, h: height/2 }, // Top-right
        { x: 0, y: height/2, w: width/2, h: height/2 }, // Bottom-left
        { x: width/2, y: height/2, w: width/2, h: height/2 } // Bottom-right
      ];
      
      for (const quad of quadrants) {
        const corner = findStrongestCornerInRegion(edges, width, height, quad);
        if (corner) corners.push(corner);
      }
      
      if (corners.length === 4) {
        console.log('‚úÖ Found 4 ticket corners');
        return corners;
      }
      
      console.log('‚ö†Ô∏è Could not find 4 distinct corners');
      return null;
    }
    
    function findStrongestCornerInRegion(edges, width, height, region) {
      let maxStrength = 0;
      let bestCorner = null;
      
      for (let y = region.y; y < region.y + region.h && y < height; y++) {
        for (let x = region.x; x < region.x + region.w && x < width; x++) {
          if (edges[y * width + x] > 0) {
            const strength = calculateCornerStrength(edges, width, height, x, y);
            if (strength > maxStrength) {
              maxStrength = strength;
              bestCorner = { x, y };
            }
          }
        }
      }
      
      return bestCorner;
    }
    
    function calculateCornerStrength(edges, width, height, x, y) {
      // Simple corner strength calculation
      let strength = 0;
      const radius = 5;
      
      for (let dy = -radius; dy <= radius; dy++) {
        for (let dx = -radius; dx <= radius; dx++) {
          const nx = x + dx;
          const ny = y + dy;
          if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
            if (edges[ny * width + nx] > 0) {
              strength++;
            }
          }
        }
      }
      
      return strength;
    }
    
    function applyPerspectiveTransform(canvas, corners) {
      console.log('üîÑ Applying perspective transformation...');
      
      // Sort corners: top-left, top-right, bottom-right, bottom-left
      const sortedCorners = sortCorners(corners);
      
      // Calculate target rectangle dimensions
      const targetWidth = Math.max(
        distance(sortedCorners[0], sortedCorners[1]),
        distance(sortedCorners[3], sortedCorners[2])
      );
      const targetHeight = Math.max(
        distance(sortedCorners[0], sortedCorners[3]),
        distance(sortedCorners[1], sortedCorners[2])
      );
      
      // Create new canvas for corrected image
      const correctedCanvas = document.createElement('canvas');
      correctedCanvas.width = targetWidth;
      correctedCanvas.height = targetHeight;
      const correctedCtx = correctedCanvas.getContext('2d');
      
      // Apply perspective transformation (simplified)
      // For a full implementation, we'd use a proper perspective matrix
      // Here we use a simplified approach
      
      try {
        correctedCtx.save();
        
        // Simple quadrilateral to rectangle mapping
        const srcCorners = sortedCorners;
        const dstCorners = [
          { x: 0, y: 0 },
          { x: targetWidth, y: 0 },
          { x: targetWidth, y: targetHeight },
          { x: 0, y: targetHeight }
        ];
        
        // Draw the transformed image (simplified transformation)
        correctedCtx.drawImage(canvas, 0, 0, targetWidth, targetHeight);
        
        correctedCtx.restore();
        
        console.log('‚úÖ Perspective transformation completed');
        return correctedCanvas.toDataURL('image/jpeg', 0.9);
        
      } catch (error) {
        console.error('‚ùå Perspective transformation failed:', error);
        return canvas.toDataURL('image/jpeg', 0.9);
      }
    }
    
    function sortCorners(corners) {
      // Sort corners clockwise starting from top-left
      const center = {
        x: corners.reduce((sum, c) => sum + c.x, 0) / corners.length,
        y: corners.reduce((sum, c) => sum + c.y, 0) / corners.length
      };
      
      return corners.sort((a, b) => {
        const angleA = Math.atan2(a.y - center.y, a.x - center.x);
        const angleB = Math.atan2(b.y - center.y, b.x - center.x);
        return angleA - angleB;
      });
    }
    
    function distance(p1, p2) {
      return Math.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2);
    }
    
    // üîç LEVEL 2: Intelligent Text Region Detection
    window.detectTextRegions = function(base64Image) {
      return new Promise((resolve, reject) => {
        try {
          console.log('üîç Starting intelligent text region detection...');
          
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          const img = new Image();
          
          img.onload = function() {
            console.log('üì∏ Image loaded for text region detection');
            
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            
            // Step 1: Convert to grayscale for analysis
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const grayData = convertToGrayscaleForRegions(imageData);
            console.log('‚ö´ Converted to grayscale for region analysis');
            
            // Step 2: Detect text-like regions using morphological operations
            const textMask = detectTextLikeRegions(grayData, canvas.width, canvas.height);
            console.log('üìù Detected text-like regions');
            
            // Step 3: Filter regions by size and density
            const filteredRegions = filterRelevantRegions(textMask, canvas.width, canvas.height);
            console.log('üéØ Filtered relevant text regions:', filteredRegions.length);
            
            if (filteredRegions.length > 0) {
              // Step 4: Create focused image with only text regions
              const focusedImage = createFocusedImage(canvas, filteredRegions);
              console.log('‚úÖ Created focused image with text regions only');
              
              resolve(focusedImage);
            } else {
              console.log('‚ö†Ô∏è No text regions detected, using original image');
              resolve(base64Image); // Fallback to original
            }
          };
          
          img.onerror = function() {
            console.error('‚ùå Failed to load image for text region detection');
            resolve(base64Image); // Fallback to original
          };
          
          img.src = base64Image;
          
        } catch (error) {
          console.error('‚ùå Text region detection failed:', error);
          resolve(base64Image); // Fallback to original
        }
      });
    };
    
    // Helper functions for text region detection
    function convertToGrayscaleForRegions(imageData) {
      const data = new Uint8ClampedArray(imageData.data.length);
      for (let i = 0; i < imageData.data.length; i += 4) {
        const gray = Math.round(0.299 * imageData.data[i] + 0.587 * imageData.data[i + 1] + 0.114 * imageData.data[i + 2]);
        data[i] = gray;
        data[i + 1] = gray;
        data[i + 2] = gray;
        data[i + 3] = imageData.data[i + 3];
      }
      return data;
    }
    
    function detectTextLikeRegions(grayData, width, height) {
      console.log('üîç Analyzing image for text-like patterns...');
      
      // Step 1: Apply adaptive thresholding
      const binaryData = applyAdaptiveThreshold(grayData, width, height);
      
      // Step 2: Morphological operations to connect text characters
      const morphData = applyMorphologicalOperations(binaryData, width, height);
      
      // Step 3: Find connected components (potential text regions)
      const components = findConnectedComponents(morphData, width, height);
      
      console.log(`üìä Found ${components.length} potential text regions`);
      return components;
    }
    
    function applyAdaptiveThreshold(data, width, height) {
      const result = new Uint8ClampedArray(data.length);
      const windowSize = 15; // Adaptive window size
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          
          // Calculate local mean in window
          let sum = 0;
          let count = 0;
          
          for (let wy = Math.max(0, y - windowSize/2); wy < Math.min(height, y + windowSize/2); wy++) {
            for (let wx = Math.max(0, x - windowSize/2); wx < Math.min(width, x + windowSize/2); wx++) {
              const widx = (wy * width + wx) * 4;
              sum += data[widx];
              count++;
            }
          }
          
          const localMean = sum / count;
          const threshold = localMean * 0.9; // Slightly below local mean
          
          const value = data[idx] < threshold ? 0 : 255; // Black text on white background
          result[idx] = value;
          result[idx + 1] = value;
          result[idx + 2] = value;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function applyMorphologicalOperations(data, width, height) {
      // Apply dilation to connect nearby text characters
      const dilated = dilateImage(data, width, height, 2);
      
      // Apply erosion to clean up noise
      const eroded = erodeImage(dilated, width, height, 1);
      
      return eroded;
    }
    
    function dilateImage(data, width, height, radius) {
      const result = new Uint8ClampedArray(data.length);
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          let maxValue = 0;
          
          // Check neighborhood
          for (let dy = -radius; dy <= radius; dy++) {
            for (let dx = -radius; dx <= radius; dx++) {
              const ny = y + dy;
              const nx = x + dx;
              
              if (ny >= 0 && ny < height && nx >= 0 && nx < width) {
                const nidx = (ny * width + nx) * 4;
                maxValue = Math.max(maxValue, data[nidx]);
              }
            }
          }
          
          result[idx] = maxValue;
          result[idx + 1] = maxValue;
          result[idx + 2] = maxValue;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function erodeImage(data, width, height, radius) {
      const result = new Uint8ClampedArray(data.length);
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          let minValue = 255;
          
          // Check neighborhood
          for (let dy = -radius; dy <= radius; dy++) {
            for (let dx = -radius; dx <= radius; dx++) {
              const ny = y + dy;
              const nx = x + dx;
              
              if (ny >= 0 && ny < height && nx >= 0 && nx < width) {
                const nidx = (ny * width + nx) * 4;
                minValue = Math.min(minValue, data[nidx]);
              }
            }
          }
          
          result[idx] = minValue;
          result[idx + 1] = minValue;
          result[idx + 2] = minValue;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function findConnectedComponents(data, width, height) {
      const visited = new Array(width * height).fill(false);
      const components = [];
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = y * width + x;
          const pixelIdx = idx * 4;
          
          if (!visited[idx] && data[pixelIdx] > 128) { // White pixel (text)
            const component = floodFill(data, visited, width, height, x, y);
            if (component.pixels.length > 50) { // Minimum size filter
              components.push(component);
            }
          }
        }
      }
      
      return components;
    }
    
    function floodFill(data, visited, width, height, startX, startY) {
      const stack = [{x: startX, y: startY}];
      const pixels = [];
      let minX = startX, maxX = startX, minY = startY, maxY = startY;
      
      while (stack.length > 0) {
        const {x, y} = stack.pop();
        const idx = y * width + x;
        
        if (x < 0 || x >= width || y < 0 || y >= height || visited[idx]) continue;
        
        const pixelIdx = idx * 4;
        if (data[pixelIdx] < 128) continue; // Not a text pixel
        
        visited[idx] = true;
        pixels.push({x, y});
        
        // Update bounding box
        minX = Math.min(minX, x);
        maxX = Math.max(maxX, x);
        minY = Math.min(minY, y);
        maxY = Math.max(maxY, y);
        
        // Add neighbors to stack
        stack.push({x: x + 1, y}, {x: x - 1, y}, {x, y: y + 1}, {x, y: y - 1});
      }
      
      return {
        pixels,
        boundingBox: {x: minX, y: minY, width: maxX - minX + 1, height: maxY - minY + 1}
      };
    }
    
    function filterRelevantRegions(components, imageWidth, imageHeight) {
      console.log('üéØ Filtering regions by size and characteristics...');
      
      return components.filter(component => {
        const bbox = component.boundingBox;
        const area = bbox.width * bbox.height;
        const aspectRatio = bbox.width / bbox.height;
        
        // Filter criteria for text regions
        const minArea = (imageWidth * imageHeight) * 0.001; // At least 0.1% of image
        const maxArea = (imageWidth * imageHeight) * 0.3;   // At most 30% of image
        const minAspectRatio = 0.1; // Not too tall
        const maxAspectRatio = 20;  // Not too wide
        
        // Text regions are usually in the middle-bottom area of receipts
        const isInRelevantArea = bbox.y > imageHeight * 0.1 && bbox.y < imageHeight * 0.9;
        
        const isValidSize = area >= minArea && area <= maxArea;
        const isValidAspectRatio = aspectRatio >= minAspectRatio && aspectRatio <= maxAspectRatio;
        
        return isValidSize && isValidAspectRatio && isInRelevantArea;
      });
    }
    
    function createFocusedImage(originalCanvas, textRegions) {
      console.log('üé® Creating focused image with text regions only...');
      
      // Create new canvas for focused image
      const focusedCanvas = document.createElement('canvas');
      focusedCanvas.width = originalCanvas.width;
      focusedCanvas.height = originalCanvas.height;
      const focusedCtx = focusedCanvas.getContext('2d');
      
      // Fill with white background
      focusedCtx.fillStyle = 'white';
      focusedCtx.fillRect(0, 0, focusedCanvas.width, focusedCanvas.height);
      
      // Copy only the text regions from original image
      for (const region of textRegions) {
        const bbox = region.boundingBox;
        
        // Add some padding around text regions
        const padding = 10;
        const x = Math.max(0, bbox.x - padding);
        const y = Math.max(0, bbox.y - padding);
        const width = Math.min(originalCanvas.width - x, bbox.width + 2 * padding);
        const height = Math.min(originalCanvas.height - y, bbox.height + 2 * padding);
        
        // Copy region from original to focused canvas
        focusedCtx.drawImage(
          originalCanvas,
          x, y, width, height, // Source rectangle
          x, y, width, height  // Destination rectangle
        );
      }
      
      console.log(`‚úÖ Created focused image with ${textRegions.length} text regions`);
      return focusedCanvas.toDataURL('image/jpeg', 0.9);
    }
    
    // Advanced Image Preprocessing for OCR Accuracy
    window.preprocessImageForOCR = function(base64Image) {
      return new Promise((resolve, reject) => {
        try {
          console.log('üñºÔ∏è Starting advanced image preprocessing...');
          
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          const img = new Image();
          
          img.onload = function() {
            console.log('üì∏ Image loaded, applying enhancements...');
            
            // Set canvas size
            canvas.width = img.width;
            canvas.height = img.height;
            
            // Draw original image
            ctx.drawImage(img, 0, 0);
            
            // Get image data
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;
            
            console.log('üîß Applying contrast enhancement...');
            // Step 1: Enhance contrast and brightness
            const contrast = 1.5; // Increase contrast
            const brightness = 10; // Slight brightness boost
            
            for (let i = 0; i < data.length; i += 4) {
              // Apply contrast and brightness to RGB channels
              data[i] = Math.min(255, Math.max(0, contrast * (data[i] - 128) + 128 + brightness)); // Red
              data[i + 1] = Math.min(255, Math.max(0, contrast * (data[i + 1] - 128) + 128 + brightness)); // Green
              data[i + 2] = Math.min(255, Math.max(0, contrast * (data[i + 2] - 128) + 128 + brightness)); // Blue
            }
            
            console.log('‚ö´ Converting to grayscale...');
            // Step 2: Convert to grayscale for better OCR
            for (let i = 0; i < data.length; i += 4) {
              const gray = Math.round(0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2]);
              data[i] = gray;     // Red
              data[i + 1] = gray; // Green
              data[i + 2] = gray; // Blue
            }
            
            console.log('üî≤ Applying binarization...');
            // Step 3: Apply adaptive binarization (convert to black/white)
            const threshold = 128;
            for (let i = 0; i < data.length; i += 4) {
              const value = data[i] > threshold ? 255 : 0;
              data[i] = value;     // Red
              data[i + 1] = value; // Green
              data[i + 2] = value; // Blue
            }
            
            console.log('üßπ Applying noise reduction...');
            // Step 4: Simple noise reduction (median filter simulation)
            const processedData = new Uint8ClampedArray(data);
            const width = canvas.width;
            const height = canvas.height;
            
            for (let y = 1; y < height - 1; y++) {
              for (let x = 1; x < width - 1; x++) {
                const idx = (y * width + x) * 4;
                
                // Get surrounding pixels
                const neighbors = [];
                for (let dy = -1; dy <= 1; dy++) {
                  for (let dx = -1; dx <= 1; dx++) {
                    const nIdx = ((y + dy) * width + (x + dx)) * 4;
                    neighbors.push(data[nIdx]);
                  }
                }
                
                // Apply median value
                neighbors.sort((a, b) => a - b);
                const median = neighbors[Math.floor(neighbors.length / 2)];
                
                processedData[idx] = median;
                processedData[idx + 1] = median;
                processedData[idx + 2] = median;
              }
            }
            
            // Apply processed data
            for (let i = 0; i < data.length; i++) {
              data[i] = processedData[i];
            }
            
            
            // Convert back to base64
            const processedBase64 = canvas.toDataURL('image/jpeg', 0.9);
            resolve(processedBase64);
          };
          
          img.onerror = function() {
            console.error('‚ùå Failed to load image for preprocessing');
            reject(new Error('Failed to load image'));
          };
          
          img.src = base64Image;
          
        } catch (error) {
          console.error('‚ùå Image preprocessing failed:', error);
          reject(error);
        }
      });
    };
    
    // Make functions available globally
    window.tesseractOCR = {
      processImage: window.processImageWithOCR
    };
    
    // Ensure Tesseract is available globally for simplified calls
    window.Tesseract = Tesseract;
    
    console.log(' Robust OCR system initialized and ready!');
    console.log(' Available strategies: Advanced Tesseract.js, OCR.space API, Simplified Tesseract');
  </script>
</head>
<body>
  <!-- PWA Installation prompt -->
  <div id="installPrompt" style="display: none; position: fixed; bottom: 20px; left: 20px; right: 20px; background: #6366F1; color: white; padding: 16px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.3); z-index: 1000;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
      <div>
        <strong>Install Tickeo</strong>
        <p style="margin: 4px 0 0 0; font-size: 14px;">Add to your home screen for quick access</p>
      </div>
      <div>
        <button id="installBtn" style="background: white; color: #6366F1; border: none; padding: 8px 16px; border-radius: 4px; margin-right: 8px; cursor: pointer;">Install</button>
        <button id="dismissBtn" style="background: transparent; color: white; border: 1px solid white; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Later</button>
      </div>
    </div>
  </div>

  <script>
    // Register Service Worker
    if ('serviceWorker' in navigator) {
      window.addEventListener('load', () => {
        navigator.serviceWorker.register('/sw.js')
          .then((registration) => {
            console.log('SW registered: ', registration);
          })
          .catch((registrationError) => {
            console.log('SW registration failed: ', registrationError);
          });
      });
    }

    // PWA Install Prompt
    let deferredPrompt;
    const installPrompt = document.getElementById('installPrompt');
    const installBtn = document.getElementById('installBtn');
    const dismissBtn = document.getElementById('dismissBtn');

    window.addEventListener('beforeinstallprompt', (e) => {
      e.preventDefault();
      deferredPrompt = e;
      installPrompt.style.display = 'block';
    });

    installBtn.addEventListener('click', async () => {
      if (deferredPrompt) {
        deferredPrompt.prompt();
        const { outcome } = await deferredPrompt.userChoice;
        console.log(`User response to the install prompt: ${outcome}`);
        deferredPrompt = null;
        installPrompt.style.display = 'none';
      }
    });

    dismissBtn.addEventListener('click', () => {
      installPrompt.style.display = 'none';
      deferredPrompt = null;
    });

    // Hide install prompt if already installed
    window.addEventListener('appinstalled', () => {
      installPrompt.style.display = 'none';
      deferredPrompt = null;
      console.log('PWA was installed');
    });
  </script>

  <script src="flutter_bootstrap.js" async></script>
</body>
</html>
