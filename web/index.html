<!DOCTYPE html>
<html>
<head>
  <!--
    If you are serving your web app in a path other than the root, change the
    href value below to reflect the base path you are serving from.

    The path provided below has to start and end with a slash "/" in order for
    it to work correctly.

    For more details:
    * https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base

    This is a placeholder for base href that will be replaced by the value of
    the `--base-href` argument provided to `flutter build`.
  -->
  <base href="$FLUTTER_BASE_HREF">

  <meta charset="UTF-8">
  <meta content="IE=Edge" http-equiv="X-UA-Compatible">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Split bills easily with friends. Scan receipts, add participants, and calculate payments automatically.">

  <!-- PWA meta tags -->
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  <meta name="apple-mobile-web-app-title" content="Tickeo">
  <meta name="theme-color" content="#6366F1">
  
  <!-- iOS icons -->
  <link rel="apple-touch-icon" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="152x152" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="180x180" href="icons/Icon-192.png">
  <link rel="apple-touch-icon" sizes="167x167" href="icons/Icon-192.png">

  <!-- Favicon -->
  <link rel="icon" type="image/png" href="favicon.png"/>
  <link rel="shortcut icon" href="favicon.png">

  <title>Tickeo - Bill Splitter</title>
  <link rel="manifest" href="manifest.json">
  
  <!-- Simplified OCR - No complex dependencies needed -->
  <script>
    console.log('üöÄ Initializing simplified OCR system (OCR.space only)...');
    
    // Simple placeholder for compatibility - OCR is handled server-side via OCR.space
    window.processImageWithOCR = async function(imageFile) {
      console.log('üìù OCR processing delegated to Dart OCR service (OCR.space)');
      throw new Error('OCR processing should be handled by Dart service');
    };
    
    console.log('‚úÖ Simplified OCR system initialized - All processing handled by OCR.space API');
  </script>

  <!-- PWA Install Prompt -->
  <script>
    // PWA Install functionality
    let deferredPrompt;
    
    window.addEventListener('beforeinstallprompt', (e) => {
      e.preventDefault();
      deferredPrompt = e;
      
      // Show install button
      const installButton = document.createElement('button');
      installButton.textContent = 'Install Tickeo';
      installButton.style.cssText = `
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: #6366F1;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 8px;
        font-size: 16px;
        cursor: pointer;
        z-index: 1000;
        box-shadow: 0 4px 12px rgba(99, 102, 241, 0.3);
      `;
      
      installButton.addEventListener('click', async () => {
        if (deferredPrompt) {
          deferredPrompt.prompt();
          const { outcome } = await deferredPrompt.userChoice;
          console.log('PWA install outcome:', outcome);
          deferredPrompt = null;
          installButton.remove();
        }
      });
      
      document.body.appendChild(installButton);
    });
    
    // Remove install button after successful install
    window.addEventListener('appinstalled', () => {
      console.log('PWA installed successfully');
      const installButton = document.querySelector('button');
      if (installButton && installButton.textContent === 'Install Tickeo') {
        installButton.remove();
      }
    });
  </script>
</head>

<body>
  <script>
    // Service Worker Registration
    if ('serviceWorker' in navigator) {
      window.addEventListener('load', () => {
        navigator.serviceWorker.register('/sw.js')
          .then((registration) => {
            console.log('SW registered: ', registration);
          })
          .catch((registrationError) => {
            console.log('SW registration failed: ', registrationError);
          });
      });
    }
  </script>

  <script src="flutter.js" defer></script>
  <script>
    window.addEventListener('load', function(ev) {
      // Download main.dart.js
      _flutter.loader.loadEntrypoint({
        serviceWorker: {
          serviceWorkerVersion: serviceWorkerVersion,
        },
        onEntrypointLoaded: function(engineInitializer) {
          engineInitializer.initializeEngine().then(function(appRunner) {
            appRunner.runApp();
          });
        }
      });
    });
  </script>
</body>
</html>



          
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          const img = new Image();
          
          img.onload = function() {
            console.log('üì∏ Image loaded for text region detection');
            
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0);
            
            // Step 1: Convert to grayscale for analysis
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const grayData = convertToGrayscaleForRegions(imageData);
            console.log('‚ö´ Converted to grayscale for region analysis');
            
            // Step 2: Detect text-like regions using morphological operations
            const textMask = detectTextLikeRegions(grayData, canvas.width, canvas.height);
            console.log('üìù Detected text-like regions');
            
            // Step 3: Filter regions by size and density
            const filteredRegions = filterRelevantRegions(textMask, canvas.width, canvas.height);
            console.log('üéØ Filtered relevant text regions:', filteredRegions.length);
            
            if (filteredRegions.length > 0) {
              // Step 4: Create focused image with only text regions
              const focusedImage = createFocusedImage(canvas, filteredRegions);
              console.log('‚úÖ Created focused image with text regions only');
              
              resolve(focusedImage);
            } else {
              console.log('‚ö†Ô∏è No text regions detected, using original image');
              resolve(base64Image); // Fallback to original
            }
          };
          
          img.onerror = function() {
            console.error('‚ùå Failed to load image for text region detection');
            resolve(base64Image); // Fallback to original
          };
          
          img.src = base64Image;
          
        } catch (error) {
          console.error('‚ùå Text region detection failed:', error);
          resolve(base64Image); // Fallback to original
        }
      });
    };
    
    // Helper functions for text region detection
    function convertToGrayscaleForRegions(imageData) {
      const data = new Uint8ClampedArray(imageData.data.length);
      for (let i = 0; i < imageData.data.length; i += 4) {
        const gray = Math.round(0.299 * imageData.data[i] + 0.587 * imageData.data[i + 1] + 0.114 * imageData.data[i + 2]);
        data[i] = gray;
        data[i + 1] = gray;
        data[i + 2] = gray;
        data[i + 3] = imageData.data[i + 3];
      }
      return data;
    }
    
    function detectTextLikeRegions(grayData, width, height) {
      console.log('üîç Analyzing image for text-like patterns...');
      
      // Step 1: Apply adaptive thresholding
      const binaryData = applyAdaptiveThreshold(grayData, width, height);
      
      // Step 2: Morphological operations to connect text characters
      const morphData = applyMorphologicalOperations(binaryData, width, height);
      
      // Step 3: Find connected components (potential text regions)
      const components = findConnectedComponents(morphData, width, height);
      
      console.log(`üìä Found ${components.length} potential text regions`);
      return components;
    }
    
    function applyAdaptiveThreshold(data, width, height) {
      const result = new Uint8ClampedArray(data.length);
      const windowSize = 15; // Adaptive window size
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          
          // Calculate local mean in window
          let sum = 0;
          let count = 0;
          
          for (let wy = Math.max(0, y - windowSize/2); wy < Math.min(height, y + windowSize/2); wy++) {
            for (let wx = Math.max(0, x - windowSize/2); wx < Math.min(width, x + windowSize/2); wx++) {
              const widx = (wy * width + wx) * 4;
              sum += data[widx];
              count++;
            }
          }
          
          const localMean = sum / count;
          const threshold = localMean * 0.9; // Slightly below local mean
          
          const value = data[idx] < threshold ? 0 : 255; // Black text on white background
          result[idx] = value;
          result[idx + 1] = value;
          result[idx + 2] = value;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function applyMorphologicalOperations(data, width, height) {
      // Apply dilation to connect nearby text characters
      const dilated = dilateImage(data, width, height, 2);
      
      // Apply erosion to clean up noise
      const eroded = erodeImage(dilated, width, height, 1);
      
      return eroded;
    }
    
    function dilateImage(data, width, height, radius) {
      const result = new Uint8ClampedArray(data.length);
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          let maxValue = 0;
          
          // Check neighborhood
          for (let dy = -radius; dy <= radius; dy++) {
            for (let dx = -radius; dx <= radius; dx++) {
              const ny = y + dy;
              const nx = x + dx;
              
              if (ny >= 0 && ny < height && nx >= 0 && nx < width) {
                const nidx = (ny * width + nx) * 4;
                maxValue = Math.max(maxValue, data[nidx]);
              }
            }
          }
          
          result[idx] = maxValue;
          result[idx + 1] = maxValue;
          result[idx + 2] = maxValue;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function erodeImage(data, width, height, radius) {
      const result = new Uint8ClampedArray(data.length);
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = (y * width + x) * 4;
          let minValue = 255;
          
          // Check neighborhood
          for (let dy = -radius; dy <= radius; dy++) {
            for (let dx = -radius; dx <= radius; dx++) {
              const ny = y + dy;
              const nx = x + dx;
              
              if (ny >= 0 && ny < height && nx >= 0 && nx < width) {
                const nidx = (ny * width + nx) * 4;
                minValue = Math.min(minValue, data[nidx]);
              }
            }
          }
          
          result[idx] = minValue;
          result[idx + 1] = minValue;
          result[idx + 2] = minValue;
          result[idx + 3] = data[idx + 3];
        }
      }
      
      return result;
    }
    
    function findConnectedComponents(data, width, height) {
      const visited = new Array(width * height).fill(false);
      const components = [];
      
      for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
          const idx = y * width + x;
          const pixelIdx = idx * 4;
          
          if (!visited[idx] && data[pixelIdx] > 128) { // White pixel (text)
            const component = floodFill(data, visited, width, height, x, y);
            if (component.pixels.length > 50) { // Minimum size filter
              components.push(component);
            }
          }
        }
      }
      
      return components;
    }
    
    function floodFill(data, visited, width, height, startX, startY) {
      const stack = [{x: startX, y: startY}];
      const pixels = [];
      let minX = startX, maxX = startX, minY = startY, maxY = startY;
      
      while (stack.length > 0) {
        const {x, y} = stack.pop();
        const idx = y * width + x;
        
        if (x < 0 || x >= width || y < 0 || y >= height || visited[idx]) continue;
        
        const pixelIdx = idx * 4;
        if (data[pixelIdx] < 128) continue; // Not a text pixel
        
        visited[idx] = true;
        pixels.push({x, y});
        
        // Update bounding box
        minX = Math.min(minX, x);
        maxX = Math.max(maxX, x);
        minY = Math.min(minY, y);
        maxY = Math.max(maxY, y);
        
        // Add neighbors to stack
        stack.push({x: x + 1, y}, {x: x - 1, y}, {x, y: y + 1}, {x, y: y - 1});
      }
      
      return {
        pixels,
        boundingBox: {x: minX, y: minY, width: maxX - minX + 1, height: maxY - minY + 1}
      };
    }
    
    function filterRelevantRegions(components, imageWidth, imageHeight) {
      console.log('üéØ Filtering regions by size and characteristics...');
      
      return components.filter(component => {
        const bbox = component.boundingBox;
        const area = bbox.width * bbox.height;
        const aspectRatio = bbox.width / bbox.height;
        
        // Filter criteria for text regions
        const minArea = (imageWidth * imageHeight) * 0.001; // At least 0.1% of image
        const maxArea = (imageWidth * imageHeight) * 0.3;   // At most 30% of image
        const minAspectRatio = 0.1; // Not too tall
        const maxAspectRatio = 20;  // Not too wide
        
        // Text regions are usually in the middle-bottom area of receipts
        const isInRelevantArea = bbox.y > imageHeight * 0.1 && bbox.y < imageHeight * 0.9;
        
        const isValidSize = area >= minArea && area <= maxArea;
        const isValidAspectRatio = aspectRatio >= minAspectRatio && aspectRatio <= maxAspectRatio;
        
        return isValidSize && isValidAspectRatio && isInRelevantArea;
      });
    }
    
    function createFocusedImage(originalCanvas, textRegions) {
      console.log('üé® Creating focused image with text regions only...');
      
      // Create new canvas for focused image
      const focusedCanvas = document.createElement('canvas');
      focusedCanvas.width = originalCanvas.width;
      focusedCanvas.height = originalCanvas.height;
      const focusedCtx = focusedCanvas.getContext('2d');
      
      // Fill with white background
      focusedCtx.fillStyle = 'white';
      focusedCtx.fillRect(0, 0, focusedCanvas.width, focusedCanvas.height);
      
      // Copy only the text regions from original image
      for (const region of textRegions) {
        const bbox = region.boundingBox;
        
        // Add some padding around text regions
        const padding = 10;
        const x = Math.max(0, bbox.x - padding);
        const y = Math.max(0, bbox.y - padding);
        const width = Math.min(originalCanvas.width - x, bbox.width + 2 * padding);
        const height = Math.min(originalCanvas.height - y, bbox.height + 2 * padding);
        
        // Copy region from original to focused canvas
        focusedCtx.drawImage(
          originalCanvas,
          x, y, width, height, // Source rectangle
          x, y, width, height  // Destination rectangle
        );
      }
      
      console.log(`‚úÖ Created focused image with ${textRegions.length} text regions`);
      return focusedCanvas.toDataURL('image/jpeg', 0.9);
    }
    
    // Advanced Image Preprocessing for OCR Accuracy
    window.preprocessImageForOCR = function(base64Image) {
      return new Promise((resolve, reject) => {
        try {
          console.log('üñºÔ∏è Starting advanced image preprocessing...');
          
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          const img = new Image();
          
          img.onload = function() {
            console.log('üì∏ Image loaded, applying enhancements...');
            
            // Set canvas size
            canvas.width = img.width;
            canvas.height = img.height;
            
            // Draw original image
            ctx.drawImage(img, 0, 0);
            
            // Get image data
            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            const data = imageData.data;
            
            console.log('üîß Applying contrast enhancement...');
            // Step 1: Enhance contrast and brightness
            const contrast = 1.5; // Increase contrast
            const brightness = 10; // Slight brightness boost
            
            for (let i = 0; i < data.length; i += 4) {
              // Apply contrast and brightness to RGB channels
              data[i] = Math.min(255, Math.max(0, contrast * (data[i] - 128) + 128 + brightness)); // Red
              data[i + 1] = Math.min(255, Math.max(0, contrast * (data[i + 1] - 128) + 128 + brightness)); // Green
              data[i + 2] = Math.min(255, Math.max(0, contrast * (data[i + 2] - 128) + 128 + brightness)); // Blue
            }
            
            console.log('‚ö´ Converting to grayscale...');
            // Step 2: Convert to grayscale for better OCR
            for (let i = 0; i < data.length; i += 4) {
              const gray = Math.round(0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2]);
              data[i] = gray;     // Red
              data[i + 1] = gray; // Green
              data[i + 2] = gray; // Blue
            }
            
            console.log('üî≤ Applying binarization...');
            // Step 3: Apply adaptive binarization (convert to black/white)
            const threshold = 128;
            for (let i = 0; i < data.length; i += 4) {
              const value = data[i] > threshold ? 255 : 0;
              data[i] = value;     // Red
              data[i + 1] = value; // Green
              data[i + 2] = value; // Blue
            }
            
            console.log('üßπ Applying noise reduction...');
            // Step 4: Simple noise reduction (median filter simulation)
            const processedData = new Uint8ClampedArray(data);
            const width = canvas.width;
            const height = canvas.height;
            
            for (let y = 1; y < height - 1; y++) {
              for (let x = 1; x < width - 1; x++) {
                const idx = (y * width + x) * 4;
                
                // Get surrounding pixels
                const neighbors = [];
                for (let dy = -1; dy <= 1; dy++) {
                  for (let dx = -1; dx <= 1; dx++) {
                    const nIdx = ((y + dy) * width + (x + dx)) * 4;
                    neighbors.push(data[nIdx]);
                  }
                }
                
                // Apply median value
                neighbors.sort((a, b) => a - b);
                const median = neighbors[Math.floor(neighbors.length / 2)];
                
                processedData[idx] = median;
                processedData[idx + 1] = median;
                processedData[idx + 2] = median;
              }
            }
            
            // Apply processed data
            for (let i = 0; i < data.length; i++) {
              data[i] = processedData[i];
            }
            
            
            // Convert back to base64
            const processedBase64 = canvas.toDataURL('image/jpeg', 0.9);
            resolve(processedBase64);
          };
          
          img.onerror = function() {
            console.error('‚ùå Failed to load image for preprocessing');
            reject(new Error('Failed to load image'));
          };
          
          img.src = base64Image;
          
        } catch (error) {
          console.error('‚ùå Image preprocessing failed:', error);
          reject(error);
        }
      });
    };
    
    // üöÄ UNIFIED ADVANCED OCR PIPELINE - Integrates ALL improvements
    window.processImageWithOCR = async function(imageFile) {
      console.log('\nüöÄ === UNIFIED ADVANCED OCR PIPELINE STARTING ===');
      console.log('üì∑ Processing image with ALL advanced improvements...');
      
      try {
        // Convert image file to base64 if needed
        let base64Image = imageFile;
        if (typeof imageFile !== 'string' || !imageFile.startsWith('data:')) {
          console.log('üì∏ Converting image to base64...');
          base64Image = await convertToBase64(imageFile);
        }
        
        console.log('‚úÖ Image ready for processing');
        
        // Start with the original image as fallback
        let processedImage = base64Image;
        
        // STEP 1: Apply automatic perspective correction (with fallback)
        try {
          console.log('üîß STEP 1: Applying automatic perspective correction...');
          const correctedImage = await window.correctPerspective(base64Image);
          processedImage = correctedImage;
          console.log('‚úÖ Perspective correction completed');
        } catch (error) {
          console.warn('‚ö†Ô∏è Perspective correction failed, using original image:', error.message);
        }
        
        // STEP 2: Apply intelligent text region detection (with fallback)
        try {
          console.log('üîç STEP 2: Applying intelligent text region detection...');
          const focusedImage = await window.detectTextRegions(processedImage);
          processedImage = focusedImage;
          console.log('‚úÖ Text region detection completed');
        } catch (error) {
          console.warn('‚ö†Ô∏è Text region detection failed, using current image:', error.message);
        }
        
        // STEP 3: Apply advanced image preprocessing (with fallback)
        try {
          console.log('üñºÔ∏è STEP 3: Applying advanced image preprocessing...');
          const preprocessedImage = await window.preprocessImageForOCR(processedImage);
          processedImage = preprocessedImage;
          console.log('‚úÖ Advanced preprocessing completed');
        } catch (error) {
          console.warn('‚ö†Ô∏è Advanced preprocessing failed, using current image:', error.message);
        }
        
        // STEP 4: Perform multi-configuration Tesseract OCR
        console.log('ü§ñ STEP 4: Performing multi-configuration Tesseract OCR...');
        
        const ocrConfigs = [
          {
            name: 'Spanish Optimized',
            options: {
              lang: 'spa+eng',
              psm: 6, // Uniform block of text
              tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú.,‚Ç¨$%-() '
            }
          },
          {
            name: 'Receipt Mode',
            options: {
              lang: 'spa+eng',
              psm: 4, // Single column of text
              tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú.,‚Ç¨$%-() '
            }
          },
          {
            name: 'Line Detection',
            options: {
              lang: 'spa+eng',
              psm: 8, // Single word
              tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú.,‚Ç¨$%-() '
            }
          },
          {
            name: 'Sparse Text',
            options: {
              lang: 'spa+eng',
              psm: 11, // Sparse text
              tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789√°√©√≠√≥√∫√±√º√Å√â√ç√ì√ö√ë√ú.,‚Ç¨$%-() '
            }
          }
        ];
        
        let bestResult = '';
        let bestConfidence = 0;
        
        for (const config of ocrConfigs) {
          try {
            console.log(`üîç Trying ${config.name} configuration...`);
            
            const result = await Tesseract.recognize(processedImage, config.options.lang, {
              logger: m => {
                if (m.status === 'recognizing text') {
                  console.log(`üìä ${config.name}: ${Math.round(m.progress * 100)}%`);
                }
              },
              tessedit_pageseg_mode: config.options.psm,
              tessedit_char_whitelist: config.options.tessedit_char_whitelist
            });
            
            const confidence = result.data.confidence;
            const text = result.data.text.trim();
            
            console.log(`‚úÖ ${config.name} completed:`);
            console.log(`   Confidence: ${confidence.toFixed(1)}%`);
            console.log(`   Text length: ${text.length} chars`);
            console.log(`   Text preview: "${text.substring(0, 100)}..."`);
            
            // Select best result based on confidence and text length
            const score = confidence * 0.7 + (text.length > 50 ? 30 : text.length * 0.6);
            if (score > bestConfidence) {
              bestResult = text;
              bestConfidence = score;
              console.log(`üèÜ New best result from ${config.name} (score: ${score.toFixed(1)})`);
            }
            
          } catch (configError) {
            console.warn(`‚ö†Ô∏è ${config.name} failed:`, configError);
          }
        }
        
        console.log('\nüéØ === UNIFIED OCR PIPELINE COMPLETED ===');
        console.log(`üèÜ Best result confidence: ${bestConfidence.toFixed(1)}`);
        console.log(`üìù Final extracted text (${bestResult.length} chars):`);
        console.log(`"${bestResult}"`);
        
        return bestResult;
        
      } catch (error) {
        console.error('‚ùå Unified OCR pipeline failed:', error);
        throw error;
      }
    };
    
    // Helper function to convert various image types to base64
    async function convertToBase64(imageFile) {
      return new Promise((resolve, reject) => {
        try {
          if (typeof imageFile === 'string' && imageFile.startsWith('data:')) {
            resolve(imageFile);
            return;
          }
          
          // Handle File or Blob objects
          if (imageFile instanceof File || imageFile instanceof Blob) {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result);
            reader.onerror = reject;
            reader.readAsDataURL(imageFile);
            return;
          }
          
          // Handle other types
          console.warn('‚ö†Ô∏è Unknown image file type, attempting direct use');
          resolve(imageFile);
          
        } catch (error) {
          reject(error);
        }
      });
    }
    
    // Make functions available globally
    window.tesseractOCR = {
      processImage: window.processImageWithOCR
    };
    
    // Ensure Tesseract is available globally for simplified calls
    window.Tesseract = Tesseract;
    
    console.log(' Robust OCR system initialized and ready!');
    console.log(' Available strategies: Advanced Tesseract.js, OCR.space API, Simplified Tesseract');
  </script>
</head>
<body>
  <!-- PWA Installation prompt -->
  <div id="installPrompt" style="display: none; position: fixed; bottom: 20px; left: 20px; right: 20px; background: #6366F1; color: white; padding: 16px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.3); z-index: 1000;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
      <div>
        <strong>Install Tickeo</strong>
        <p style="margin: 4px 0 0 0; font-size: 14px;">Add to your home screen for quick access</p>
      </div>
      <div>
        <button id="installBtn" style="background: white; color: #6366F1; border: none; padding: 8px 16px; border-radius: 4px; margin-right: 8px; cursor: pointer;">Install</button>
        <button id="dismissBtn" style="background: transparent; color: white; border: 1px solid white; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Later</button>
      </div>
    </div>
  </div>

  <script>
    // Register Service Worker
    if ('serviceWorker' in navigator) {
      window.addEventListener('load', () => {
        navigator.serviceWorker.register('/sw.js')
          .then((registration) => {
            console.log('SW registered: ', registration);
          })
          .catch((registrationError) => {
            console.log('SW registration failed: ', registrationError);
          });
      });
    }

    // PWA Install Prompt
    let deferredPrompt;
    const installPrompt = document.getElementById('installPrompt');
    const installBtn = document.getElementById('installBtn');
    const dismissBtn = document.getElementById('dismissBtn');

    window.addEventListener('beforeinstallprompt', (e) => {
      e.preventDefault();
      deferredPrompt = e;
      installPrompt.style.display = 'block';
    });

    installBtn.addEventListener('click', async () => {
      if (deferredPrompt) {
        deferredPrompt.prompt();
        const { outcome } = await deferredPrompt.userChoice;
        console.log(`User response to the install prompt: ${outcome}`);
        deferredPrompt = null;
        installPrompt.style.display = 'none';
      }
    });

    dismissBtn.addEventListener('click', () => {
      installPrompt.style.display = 'none';
      deferredPrompt = null;
    });

    // Hide install prompt if already installed
    window.addEventListener('appinstalled', () => {
      installPrompt.style.display = 'none';
      deferredPrompt = null;
      console.log('PWA was installed');
    });
  </script>

  <script src="flutter_bootstrap.js" async></script>
</body>
</html>
